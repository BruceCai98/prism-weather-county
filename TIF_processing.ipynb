{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab81707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading county boundaries ...\n",
      "Reading sample PRISM raster ...\n",
      "Rasterizing counties to PRISM grid ...\n",
      "Building sparse index for each county ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3109/3109 [00:00<00:00, 8660.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving mapping: D:/desktop/weather_data/county_to_idx.npy\n",
      "County → pixel mapping completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# STEP 1 — Build county → pixel mapping (one-time)\n",
    "# ===============================================\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.features import rasterize\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "COUNTY_FILE = r\"D:/desktop/weather_data/geojson-counties-fips.json\"   # 你的县边界文件\n",
    "SAMPLE_TIF  = r\"D:/desktop/weather_data/prism_raw/ppt/1990/ppt_19900101.tif\"\n",
    "\n",
    "OUT_MAP = r\"D:/desktop/weather_data/county_to_idx.npy\"\n",
    "\n",
    "print(\"Loading county boundaries ...\")\n",
    "gdf = gpd.read_file(COUNTY_FILE)\n",
    "gdf = gdf[~gdf[\"STATE\"].isin([\"02\", \"15\", \"72\"])].copy()\n",
    "gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "gdf[\"id\"] = gdf[\"id\"].astype(int)\n",
    "\n",
    "print(\"Reading sample PRISM raster ...\")\n",
    "with rasterio.open(SAMPLE_TIF) as src:\n",
    "    height = src.height\n",
    "    width  = src.width\n",
    "    transform = src.transform\n",
    "\n",
    "print(\"Rasterizing counties to PRISM grid ...\")\n",
    "shapes = [(geom, fips) for geom, fips in zip(gdf.geometry, gdf[\"id\"])]\n",
    "\n",
    "county_map = rasterize(\n",
    "    shapes,\n",
    "    out_shape=(height, width),\n",
    "    transform=transform,\n",
    "    fill=-1,\n",
    "    dtype=np.int32\n",
    ")\n",
    "\n",
    "flat = county_map.reshape(-1)\n",
    "\n",
    "print(\"Building sparse index for each county ...\")\n",
    "county_to_idx = {}\n",
    "for fips in tqdm(gdf[\"id\"]):\n",
    "    county_to_idx[fips] = np.where(flat == fips)[0].astype(np.int32)\n",
    "\n",
    "print(\"Saving mapping:\", OUT_MAP)\n",
    "np.save(OUT_MAP, county_to_idx, allow_pickle=True)\n",
    "print(\"County → pixel mapping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da67eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def process_daily_tif(date_str, tif_paths, county_to_idx):\n",
    "    \"\"\"\n",
    "    tif_paths = {\"ppt\": path1, \"tmin\": path2, \"tmax\": path3}\n",
    "    return list of (date, fips, ppt, tmin, tmax)\n",
    "    \"\"\"\n",
    "    gpu_arrays = {}\n",
    "\n",
    "    # Load all 3 variables into GPU\n",
    "    for element, tif_path in tif_paths.items():\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            data = src.read(1).astype(np.float32)\n",
    "        gpu_arrays[element] = cp.asarray(data.reshape(-1))\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Loop counties\n",
    "    for fips, idx in county_to_idx.items():\n",
    "        gpu_idx = cp.asarray(idx)\n",
    "\n",
    "        ppt  = float(cp.nanmean(gpu_arrays[\"ppt\"][gpu_idx]).get())\n",
    "        tmin = float(cp.nanmean(gpu_arrays[\"tmin\"][gpu_idx]).get())\n",
    "        tmax = float(cp.nanmean(gpu_arrays[\"tmax\"][gpu_idx]).get())\n",
    "\n",
    "        rows.append((date_str, fips, ppt, tmin, tmax))\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd18cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty counties: [51670, 51600, 51830, 51580, 51610, 51678, 51685, 51570]\n",
      "Counties kept after dropping empty ones: 3101\n",
      "=== Processing year 1990 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1990.csv\n",
      "=== Processing year 1991 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1991.csv\n",
      "=== Processing year 1992 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1992.csv\n",
      "=== Processing year 1993 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1993.csv\n",
      "=== Processing year 1994 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1994.csv\n",
      "=== Processing year 1995 ===\n",
      "Missing: D:\\desktop\\weather_data\\prism_raw\\ppt\\1995\\ppt_19950101.tif\n",
      "Missing: D:\\desktop\\weather_data\\prism_raw\\ppt\\1995\\ppt_19950102.tif\n",
      "Missing: D:\\desktop\\weather_data\\prism_raw\\ppt\\1995\\ppt_19950103.tif\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1995.csv\n",
      "=== Processing year 1996 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1996.csv\n",
      "=== Processing year 1997 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1997.csv\n",
      "=== Processing year 1998 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1998.csv\n",
      "=== Processing year 1999 ===\n",
      "Missing: D:\\desktop\\weather_data\\prism_raw\\tmin\\1999\\tmin_19990313.tif\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_1999.csv\n",
      "=== Processing year 2000 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2000.csv\n",
      "=== Processing year 2001 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2001.csv\n",
      "=== Processing year 2002 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2002.csv\n",
      "=== Processing year 2003 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2003.csv\n",
      "=== Processing year 2004 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2004.csv\n",
      "=== Processing year 2005 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2005.csv\n",
      "=== Processing year 2006 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2006.csv\n",
      "=== Processing year 2007 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2007.csv\n",
      "=== Processing year 2008 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2008.csv\n",
      "=== Processing year 2009 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2009.csv\n",
      "=== Processing year 2010 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2010.csv\n",
      "=== Processing year 2011 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2011.csv\n",
      "=== Processing year 2012 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2012.csv\n",
      "=== Processing year 2013 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2013.csv\n",
      "=== Processing year 2014 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2014.csv\n",
      "=== Processing year 2015 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2015.csv\n",
      "=== Processing year 2016 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2016.csv\n",
      "=== Processing year 2017 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2017.csv\n",
      "=== Processing year 2018 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2018.csv\n",
      "=== Processing year 2019 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2019.csv\n",
      "=== Processing year 2020 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2020.csv\n",
      "=== Processing year 2021 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2021.csv\n",
      "=== Processing year 2022 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2022.csv\n",
      "=== Processing year 2023 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2023.csv\n",
      "=== Processing year 2024 ===\n",
      "  Year written: D:\\desktop\\weather_data\\prism_daily_county_2024.csv\n",
      "All years done!\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# STEP 3 — Main pipeline: loop daily files (safe)\n",
    "# ===============================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import date, timedelta\n",
    "import numpy as np  # 别忘了 import\n",
    "# from your_module import process_daily_tif  # 确保已经定义好了\n",
    "\n",
    "RAW_DIR = Path(r\"D:/desktop/weather_data/prism_raw\")\n",
    "OUT_DIR = Path(r\"D:/desktop/weather_data\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 总表（所有年份汇总）的路径（可选）\n",
    "OUT_ALL = OUT_DIR / \"prism_daily_county_all.csv\"\n",
    "\n",
    "# load county index\n",
    "county_to_idx = np.load(\n",
    "    r\"D:/desktop/weather_data/county_to_idx.npy\",\n",
    "    allow_pickle=True\n",
    ").item()\n",
    "empty_fips = [fips for fips, idx in county_to_idx.items() if idx is None or len(idx) == 0]\n",
    "print(\"Empty counties:\", empty_fips)\n",
    "# 过滤掉没有任何像素的县（len(idx) == 0）\n",
    "county_to_idx = {\n",
    "    fips: np.asarray(idx, dtype=np.int32)\n",
    "    for fips, idx in county_to_idx.items()\n",
    "    if idx is not None and len(idx) > 0\n",
    "}\n",
    "print(\"Counties kept after dropping empty ones:\", len(county_to_idx))\n",
    "\n",
    "ELEMENTS = [\"ppt\", \"tmin\", \"tmax\"]\n",
    "YEARS = range(1990, 2025)\n",
    "\n",
    "def find_tif(element, dt):\n",
    "    return RAW_DIR / element / str(dt.year) / f\"{element}_{dt:%Y%m%d}.tif\"\n",
    "\n",
    "def process_one_day(dt):\n",
    "    \"\"\"处理单天，返回若干 (date, fips, ppt, tmin, tmax)\"\"\"\n",
    "    date_str = dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    paths = {}\n",
    "    for e in ELEMENTS:\n",
    "        p = find_tif(e, dt)\n",
    "        if not p.exists():\n",
    "            print(\"Missing:\", p)\n",
    "            return []\n",
    "        paths[e] = p\n",
    "\n",
    "    # GPU 计算\n",
    "    return process_daily_tif(date_str, paths, county_to_idx)\n",
    "\n",
    "\n",
    "def iter_dates_for_year(year):\n",
    "    d = date(year, 1, 1)\n",
    "    end = date(year, 12, 31)\n",
    "    while d <= end:\n",
    "        yield d\n",
    "        d += timedelta(days=1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    for y in YEARS:\n",
    "        print(f\"=== Processing year {y} ===\")\n",
    "        year_rows = []\n",
    "\n",
    "        # 不用线程池，逐天顺序处理\n",
    "        for d in iter_dates_for_year(y):\n",
    "            rows = process_one_day(d)\n",
    "            if rows:\n",
    "                year_rows.extend(rows)\n",
    "\n",
    "        if not year_rows:\n",
    "            print(f\"No data for year {y}, skip writing.\")\n",
    "            continue\n",
    "\n",
    "        df_year = pd.DataFrame(year_rows, columns=[\"date\",\"fips\",\"ppt\",\"tmin\",\"tmax\"])\n",
    "\n",
    "        out_year_csv = OUT_DIR / f\"prism_daily_county_{y}.csv\"\n",
    "        df_year.to_csv(out_year_csv, index=False)\n",
    "        print(\"  Year written:\", out_year_csv)\n",
    "\n",
    "        del df_year\n",
    "        del year_rows\n",
    "\n",
    "    print(\"All years done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f2261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
